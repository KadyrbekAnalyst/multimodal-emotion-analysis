{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 15:29:28.055289: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-18 15:29:28.134791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-18 15:29:28.134848: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-18 15:29:28.134933: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-18 15:29:28.151468: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-18 15:29:28.152085: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-18 15:29:29.869556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure results directory exists\n",
    "os.makedirs(\"results/plots\", exist_ok=True)\n",
    "\n",
    "# Placeholder paths for test datasets\n",
    "fer2013_test_data = \"FER-2013/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Section 2: Load and Preprocess Data\n",
    "# Define functions for loading and preprocessing FER2013 dataset\n",
    "\n",
    "def load_fer2013_images(data_dir):\n",
    "    \"\"\"\n",
    "    Load images from FER2013 directories structured by class names.\n",
    "    :param data_dir: Path to directory containing class folders\n",
    "    :return: List of tuples (image path, label)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    classes = os.listdir(data_dir)\n",
    "    for label in classes:\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for file in os.listdir(class_dir):\n",
    "                if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    data.append((os.path.join(class_dir, file), label))\n",
    "    print(f\"Loaded {len(data)} images from {len(classes)} classes.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_deepface_fer2013(image_data, sample_size=100):\n",
    "    \"\"\"\n",
    "    Validate DeepFace on images in FER2013 dataset.\n",
    "    :param image_data: List of tuples (image path, label)\n",
    "    :param sample_size: Number of samples to process\n",
    "    :return: Ground truth and predicted labels\n",
    "    \"\"\"\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    \n",
    "    # Sampling data\n",
    "    sampled_data = image_data[:sample_size]\n",
    "    print(f\"Validating DeepFace on {len(sampled_data)} samples...\")\n",
    "    \n",
    "    for img_path, label in tqdm(sampled_data):\n",
    "        ground_truth.append(label)\n",
    "        \n",
    "        try:\n",
    "            # Load image using OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Analyze image with DeepFace\n",
    "            result = DeepFace.analyze(img_path=img, actions=['emotion'], enforce_detection=False, silent=True)\n",
    "            predicted_label = result[0]['dominant_emotion']\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            predicted_label = \"error\"\n",
    "        predictions.append(predicted_label)\n",
    "    \n",
    "    return ground_truth, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Section 4: Visualize Results\n",
    "# Define visualization functions for DeepFace validation results\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, save_path):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # Удаляем старый файл, если он существует\n",
    "    if os.path.exists(save_path):\n",
    "        os.remove(save_path)\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def visualize_results(ground_truth, predictions, save_dir):\n",
    "    \"\"\"\n",
    "    Generate confusion matrix and classification report\n",
    "    :param ground_truth: List of ground truth labels\n",
    "    :param predictions: List of predicted labels\n",
    "    :param save_dir: Directory to save plots\n",
    "    \"\"\"\n",
    "    labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "    cm = confusion_matrix(ground_truth, predictions, labels=labels)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(ground_truth, predictions, labels=labels))\n",
    "    \n",
    "    # Save confusion matrix plot\n",
    "    cm_path = os.path.join(save_dir, \"fer2013_confusion_matrix.png\")\n",
    "    plot_confusion_matrix(cm, labels, \"DeepFace Validation on FER2013\", cm_path)\n",
    "    print(f\"Confusion matrix saved at: {cm_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FER2013 validation with DeepFace...\n",
      "Loaded 7178 images from 7 classes.\n",
      "Validating DeepFace on 7000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [03:33<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.52      0.43      0.47       958\n",
      "     disgust       0.62      0.45      0.52       111\n",
      "        fear       0.40      0.42      0.41      1024\n",
      "       happy       0.78      0.76      0.77      1774\n",
      "     neutral       0.47      0.54      0.50      1233\n",
      "         sad       0.39      0.41      0.40      1069\n",
      "    surprise       0.77      0.70      0.74       831\n",
      "\n",
      "    accuracy                           0.56      7000\n",
      "   macro avg       0.56      0.53      0.54      7000\n",
      "weighted avg       0.57      0.56      0.56      7000\n",
      "\n",
      "Confusion matrix saved at: results/plots/fer2013_confusion_matrix.png\n",
      "Validation complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# ## Section 5: Run Validation on FER2013\n",
    "print(\"\\nStarting FER2013 validation with DeepFace...\")\n",
    "fer2013_data = load_fer2013_images(fer2013_test_data)\n",
    "ground_truth, predictions = validate_deepface_fer2013(fer2013_data, sample_size=7000)\n",
    "visualize_results(ground_truth, predictions, save_dir=\"results/plots\")\n",
    "\n",
    "print(\"Validation complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized. Proceed with loading data and validating models.\n"
     ]
    }
   ],
   "source": [
    "# ## Section 6: Summary and Next Steps\n",
    "# Provide a summary of the validation and propose weight adjustments\n",
    "\n",
    "print(\"Notebook initialized. Proceed with loading data and validating models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
